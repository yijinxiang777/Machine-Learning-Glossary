---
layout: default
title: Machine Learning in Practice
parent: Introduction
nav_order: 2
---

# Machine Learning in Practice: Adapting to Problems and Challenges
{: .no_toc }

---
Machine Learning and Artificial Intelligence implementations often try to balance two counterposing objectives. On the one hand, machine learning scientists and programmers often rely on variable abstraction to develop generalizable software programs that do not accommodate specific contextual features of the data. On the other hand, the most successful implementations of machine learning have to account for issues or problems that arise when a specific dataset is used to generate an algorithm with a specific purpose.   

For example, Caruana et al (2015) relied on generalized additive models (GAMs) to develop an algorithm for triaging high risk pneumonia patients for hospitalization versus lower risk pneumonia patients for outpatient treatment. However, in its initial implementation, the algorithm predicted that individuals with asthma were less likely to die from pneumonia, compared to non-asthmatics. Additional exploration suggested that this unexpected association was explained by the fact that hospital protocol dictated that asthmatic patients with pneumonia were immediately transferred to the ICU, where they received a higher quality of care compared to the general population. For this reason, asthmatic patients had a lower mortality risk. To address this, the authors incorporated a rule-based logistic regression model that would override their initial GAMs when the training data observation was an asthmatic patient, even if the accuracy of the resulting meta-model was lower than the original ML algorithm. 

Similarly, Zech et al sought to develop deep learning algorithms using radiological data to detect pneumonia in patients recruited at three different hospital groups (i.e., National Institutes of Health Clinical Center (NIH) data, Indiana University Network for Patient Care (IU), and Mount Sinai Hospital (MSH)). Convolutional neural networks (CNNs) were trained using chest x-rays with three different training set combinations, NIH training data, MSH training data, and a combined NIH-MSH training dataset. The authors found much lower prediction accuracy than expected, which was correlated with hospital or department of origin. They found that CNNs became sensitive to features of the hospital or x-ray machine, rather than the patient characteristics encoded in the images. This finding aligns well with other discoveries on the properties of ML for image analysis, including CNNs. Machine learning and AI algorithms can be influenced by minor differences in irrelevant or misleading contextual factors (i.e.,different image processing protocols from different hospitals, devices from different manufacturers used to obtain radiographic images, background noise in the image, etc), or by the prevalence of pneumonia between hospital systems and departments. Essentially, the algorithms relied on contextual features of the images (e.g., resolution and color scheme) that were not relevant to the patients pneumonia status, and which led to poor performance when the algorithms were implemented settings with different contextual features.  

Often, machine learning algorithms are developed to maximize certain features of the algorithm’s performance. For example, researchers often seek to maximize sensitivity and specificity, which is equivalent to maximizing the area under the ROC curve.17 Yet this can lead to a number of false positive predictions. Under resource constrained settings in which clinicians may seek to allocate expensive or invasive treatments, there is a strong motive for minimizing false positive observations. Zheng et al sought to predict the risk of HIV seroconversion in order to more effectively allocate HIV pre-exposure prophylaxis (PrEP) under resource constrained settings. To limit the number of false positive cases, Zheng et al developed a loss function for a family of algorithms that sought to maximize sensitivity subject to constraints on the false positive rate. In effect, Zheng et al incorporated contextual information on the nature of the intervention that would result from the algorithm’s output in order to limit the occurrence of undesirable outcomes (i.e., giving PrEP to HIV-negative individuals who are unlikely to experience seroconversion).  

Each of these three examples demonstrate that one should rarely ever develop and implement a general machine learning algorithm in any given setting. Rather, one should seek to incorporate contextual factors relevant to the research question at hand that may have a bearing on how the algorithm performs. In effect, these examples demonstrate the importance of context and subject matter specifics when constructing ML/AI algorithms.  
